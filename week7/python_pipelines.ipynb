{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling pipelines\n",
    "=================\n",
    "\n",
    "Thinking about modeling as a series of transformations is really helpful.\n",
    "Pipelines and functional transformations are the cleanest way to preprocess the data.\n",
    "It has its roots in Category theory from mathematics.\n",
    "\n",
    "Functional transformers are reusable and you can create many complicated things with them (think about Lego blocks).\n",
    "\n",
    "Assumptions\n",
    "-------------------\n",
    "\n",
    "1. We will be using scikit-learn interface to pipelines.\n",
    "2. We will use pandas dataframes as inputs to pipelines (useful).\n",
    "\n",
    "There are 2 types of building blocks of machine learning pipelines: transformers and estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers\n",
    "---------\n",
    "\n",
    "Blocks that have input and output and can be chained with other transformers.\n",
    "\n",
    "For example\n",
    "\n",
    "```\n",
    "Data -> [ Select variables ] -> [ Normalize ] -> [ Reduce dimensions ] -> Output\n",
    "```\n",
    "\n",
    "`[ Select variables ]` - transformer for selecting variables\n",
    "\n",
    "`[ Normalize ]` - normalization step\n",
    "\n",
    "`[ Reduce dimensions ]` - dimension reduction\n",
    "\n",
    "\n",
    "-------------------\n",
    "\n",
    "Because every transformer has the same type of data as input and output altogether they \n",
    "also form a transformer.\n",
    "\n",
    "```\n",
    "Input -> [ [ Select variables ] -> [ Normalize ] -> [ Reduce dimensions ] ] -> Output\n",
    "\n",
    "Input -> [               Data preprocessing transformation                ] -> Output\n",
    "```\n",
    "\n",
    "-------------------\n",
    "\n",
    "An example of transformer that does nothing\n",
    "\n",
    "```python\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class LazyTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        return x\n",
    "```\n",
    "\n",
    "-------------------\n",
    "\n",
    "Notice that there are 2 methods:\n",
    "\n",
    "1. **fit** - learns the information about the data - it becomes a stateful transformer\n",
    "2. **transform** - applies the transformation \n",
    "\n",
    "There are 2 types of transformers:\n",
    "1. **stateful** - they learn something when calling fit method\n",
    "2. **stateless** - they don't learn anything\n",
    "\n",
    "**Why stateless transformers are useful?**\n",
    "\n",
    "Transformers that don't need historical data to learn can be used in a type of learning\n",
    "called `online learning`. This type of learning fits pipelines beacuse it is an algorithm\n",
    "that uses the stream of observations to learn.\n",
    "\n",
    "It doesn't keep the history so there would be no way to use stateful transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than modeling\n",
    "================\n",
    "\n",
    "Using pipelines is not limited to machine learning.\n",
    "It is as easy as defining a few rules to write modular and composable classes.\n",
    "\n",
    "Let's say you build a Data Engineering platform.\n",
    "\n",
    "Define a set of inputs (Let's say dataframes): A,B,C,D,E\n",
    "\n",
    "```python\n",
    "class Merge(Transformation):\n",
    "    input = (A,B)\n",
    "    output = (C)\n",
    "\n",
    "    def transform(A: DataFrame, B: DataFrame) -> DataFrame:\n",
    "        ...\n",
    "        return C\n",
    "        \n",
    "class ExtractUsefulFeatures(Transformation):\n",
    "    input = (C)\n",
    "    output = (D,E)\n",
    "    \n",
    "    def transform(C: DataFrame) -> (DataFrame, DataFrame):\n",
    "        ...\n",
    "        return (D,E)\n",
    "```\n",
    "\n",
    "Notice that every transform method accepts and outputs DataFrames. It is important to decouple IO operations\n",
    "\n",
    "\n",
    "```python\n",
    "def transform() -> DataFrame:\n",
    "    A = load_A()\n",
    "    B = load_B()\n",
    "    ...\n",
    "    return C\n",
    "```\n",
    "\n",
    "would be a mistake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn pipelines to the rescue\n",
    "-------------\n",
    "\n",
    "Fortunately scikit-learn provides a set of helpful functions to deal with pipelines.\n",
    "2 of them are the most important:\n",
    "\n",
    "1. `sklearn.pipeline.make_pipeline`\n",
    "\n",
    "2. `sklearn.pipeline.make_union`\n",
    "\n",
    "    Creates a union of transformers\n",
    "    \n",
    "    ```\n",
    "    \n",
    "             transformer 1\n",
    "           /               \\\n",
    "          /                 \\\n",
    "    input                     output\n",
    "          \\                 /    \n",
    "           \\               /\n",
    "             transformer 2\n",
    "             \n",
    "    ```\n",
    "             \n",
    "    It is useful when the dataset consists of several types of data that one must \n",
    "    deal with separately.\n",
    "\n",
    "\n",
    "Alternative way to define pipelines\n",
    "--------------\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "```\n",
    "\n",
    "It is useful to name the steps because sometimes we want to control the steps from outside - for example when searching for parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heterogenous data\n",
    "==========================\n",
    "\n",
    "Normally datasets are not matrices of numbers.\n",
    "In real life it will be a mix of:\n",
    "- categorical features\n",
    "- numerical features\n",
    "- dates\n",
    "- text data\n",
    "- with missing values / without missing values\n",
    "\n",
    "Still you must create 1 pipeline to process all these types of information.\n",
    "\n",
    "Possible transformations:\n",
    "- **categorical features**:\n",
    "    - one hot encoding - converting to binary values\n",
    "    - convert to numerical values - by using a hash of categorical variable\n",
    "    - target averaging - replace categorical feature with an average of the target\n",
    "    \n",
    "- **numerical features**:\n",
    "    - fill missing values\n",
    "    - create bins with ranges \n",
    "    - normalize, scale\n",
    "    \n",
    "- **text**\n",
    "    - use bag of words vectorization\n",
    "    - word2vec, sentence2vec\n",
    "\n",
    "- **dates**\n",
    "    - extract years, months, days, days of week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implimentation\n",
    "==========================\n",
    "\n",
    "\n",
    "Normally the data comes in various shapes and formats\n",
    "\n",
    "We need a way merge together sklearn and pandas dataframes in order to do something like this:\n",
    "\n",
    "```python\n",
    "pipeline = make_pipeline(\n",
    "     CleanData(),\n",
    "     make_union(\n",
    "         make_pipeline(\n",
    "             Selector('text_column'), \n",
    "             CountVectorizer()\n",
    "         ),\n",
    "         make_pipeline(\n",
    "             Selector('numerical_column_1', 'numerical_column_2'), \n",
    "             StandardScaler()\n",
    "         ),\n",
    "         make_pipeline(\n",
    "             Selector('categorical_column'), \n",
    "             OneHotEncoder()\n",
    "         ),\n",
    "      ),\n",
    "      model\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
